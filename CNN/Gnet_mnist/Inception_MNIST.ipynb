{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b39c8ece9915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import layer_utils\n",
    "from tensorflow.keras.utils.data_utils import get_file\n",
    "from tensorflowf.keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras.utils.vis_utils import model_to_dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow.keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist data\n",
    "(X_train_orig, Y_train_orig), (X_test_orig, Y_test_orig) = tf.keras.datasets.mnist.load_data(path='mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a picture\n",
    "index = 10\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[index])))\n",
    "print (X_train_orig[index].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape dataset from (60000, 28, 28) to (60000, 28, 28, 1)\n",
    "img_rows, img_cols = 28,28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train_orig = X_train_orig.reshape(X_train_orig.shape[0], 1, img_rows, img_cols)\n",
    "    X_test_orig = X_test_orig.reshape(X_test_orig.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train_orig = X_train_orig.reshape(X_train_orig.shape[0], img_rows, img_cols, 1)\n",
    "    X_test_orig = X_test_orig.reshape(X_test_orig.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    # Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 10).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 10).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MNIST_model(input_shape, classes = 10):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "  \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(32, (5, 5), name = 'conv1',padding = 'same')(X_input)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2),strides = (2, 2), name = 'max_pool1')(X)\n",
    "    \n",
    "    # branch1\n",
    "    # CONV 1X1\n",
    "    b1_X = Conv2D(64, (1, 1), name = 'conv2',padding = 'valid')(X)\n",
    "    b1_X = BatchNormalization(axis = 3, name = 'bn2')(b1_X)\n",
    "    b1_X = Activation('relu')(b1_X)\n",
    "    b1_X = MaxPooling2D((3, 3), name='max_pool2')(b1_X)\n",
    "\n",
    "    # branch2\n",
    "    # CONV 1x1 -> CONV 3x3\n",
    "    b2_X = Conv2D(64, (1, 1), name = 'conv3',padding = 'same')(X)\n",
    "    b2_X = BatchNormalization(axis = 3, name = 'bn3')(b2_X)\n",
    "    b2_X = Activation('relu')(b2_X)\n",
    "    b2_X = Conv2D(64, (3, 3), name = 'conv4',padding = 'same')(b2_X)\n",
    "    b2_X = BatchNormalization(axis = 3, name = 'bn4')(b2_X)\n",
    "    b2_X = Activation('relu')(b2_X)\n",
    "    b2_X = MaxPooling2D((3, 3), name='max_pool3')(b2_X)\n",
    "    \n",
    "    # branch3\n",
    "    # CONV 1x1 -> CONV 5x5\n",
    "    b3_X = Conv2D(64, (1, 1), name = 'conv5',padding = 'same')(X)\n",
    "    b3_X = BatchNormalization(axis = 3, name = 'bn5')(b3_X)\n",
    "    b3_X = Activation('relu')(b3_X)\n",
    "    b3_X = Conv2D(64, (5, 5), name = 'conv6',padding = 'same')(b3_X)\n",
    "    b3_X = BatchNormalization(axis = 3, name = 'bn6')(b3_X)\n",
    "    b3_X = Activation('relu')(b3_X)\n",
    "    b3_X = MaxPooling2D((3, 3), name='max_pool4')(b3_X)\n",
    "    \n",
    "    # branch4\n",
    "    # MAXPOOL 3x3 -> CONV 1x1\n",
    "    b4_X = MaxPooling2D((3, 3), name='max_pool5')(X)\n",
    "    b4_X = Conv2D(64, (1, 1), name = 'conv7',padding = 'same')(b4_X)\n",
    "    b4_X = BatchNormalization(axis = 3, name = 'bn7')(b4_X)\n",
    "    b4_X = Activation('relu')(b4_X)\n",
    "    \n",
    "    # CONCAT\n",
    "    concat = keras.layers.concatenate([b1_X, b2_X, b3_X, b4_X],axis=3)\n",
    "    X = Activation('relu')(concat)\n",
    "    \n",
    "    #X = Flatten()(X)\n",
    "    X = Dense(128, activation='relu', name='fc1')(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc2')(X)\n",
    "    # Create model. \n",
    "    model = Model(inputs = X_input, outputs = X, name='MNIST')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTmodel = MNIST_model((28,28,1),classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTmodel.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTmodel.fit(X_train, Y_train, epochs = 10, batch_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTmodel.save('MNISTmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = MNISTmodel.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNISTmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(MNISTmodel, to_file='model.png')\n",
    "SVG(model_to_dot(MNISTmodel).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(MNISTmodel, 'MNISTmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
